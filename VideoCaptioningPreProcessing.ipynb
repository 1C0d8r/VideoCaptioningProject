{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 15 18:49:42 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@author: santanu\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model \n",
    "import fire\n",
    "from elapsedtimer import ElapsedTimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<br>\n",
    "VideoCaptioningPreProcessing will extract the Dense features from the <br>\n",
    "images in the Video frame using a Pre-trained VGG16 CNN Model<br>\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCaptioningPreProcessing:\n",
    "    \n",
    "    def __init__(self,video_dest,feat_dir,\n",
    "                 temp_dest,img_dim=224,channels=3,\n",
    "                 batch_size=128,frames_step=80):\n",
    "        \n",
    "        self.img_dim = img_dim\n",
    "        self.channels = channels\n",
    "        self.video_dest = video_dest\n",
    "        self.feat_dir = feat_dir\n",
    "        self.temp_dest = temp_dest\n",
    "        self.batch_cnn = batch_size\n",
    "        self.frames_step = frames_step\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the video into image frames at a specified sampling rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def video_to_frames(self,video):\n",
    "        \n",
    "        with open(os.devnull, \"w\") as ffmpeg_log:\n",
    "            if os.path.exists(self.temp_dest):\n",
    "                print(\" cleanup: \" + self.temp_dest + \"/\")\n",
    "                shutil.rmtree(self.temp_dest)\n",
    "            os.makedirs(self.temp_dest)\n",
    "            video_to_frames_cmd = [\"ffmpeg\",\n",
    "                                       \n",
    "                                       '-y',\n",
    "                                       '-i', video,  \n",
    "                                       '-vf', \"scale=400:300\", \n",
    "                                       '-qscale:v', \"2\", \n",
    "                                       '{0}/%06d.jpg'.format(self.temp_dest)]\n",
    "            subprocess.call(video_to_frames_cmd,\n",
    "                            stdout=ffmpeg_log, stderr=ffmpeg_log)\n",
    "                        \n",
    "# Load the pre-trained VGG16 Model and extract the dense features as output \n",
    "    def model_cnn_load(self):\n",
    "         model = VGG16(weights = \"imagenet\", include_top=True,input_shape = (self.img_dim,self.img_dim,self.channels))\n",
    "         out = model.layers[-2].output\n",
    "         model_final = Model(inputs=model.input,outputs=out)\n",
    "         return model_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the video images "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
